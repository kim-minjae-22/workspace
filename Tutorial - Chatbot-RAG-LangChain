{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install -q langchain langchain-community langchain_huggingface chromadb wikipedia","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:00:57.946807Z","iopub.execute_input":"2024-11-05T05:00:57.947228Z","iopub.status.idle":"2024-11-05T05:01:43.958146Z","shell.execute_reply.started":"2024-11-05T05:00:57.947192Z","shell.execute_reply":"2024-11-05T05:01:43.956881Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom langchain_community.document_loaders import WikipediaLoader\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain_community.vectorstores import Chroma\nfrom langchain.chains import RetrievalQA\nfrom langchain.prompts import PromptTemplate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:04:58.001381Z","iopub.execute_input":"2024-11-05T05:04:58.002061Z","iopub.status.idle":"2024-11-05T05:04:58.008583Z","shell.execute_reply.started":"2024-11-05T05:04:58.002018Z","shell.execute_reply":"2024-11-05T05:04:58.007409Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"YOUR-API-TOKEN\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:54:01.729981Z","iopub.execute_input":"2024-11-05T05:54:01.731091Z","iopub.status.idle":"2024-11-05T05:54:01.736055Z","shell.execute_reply.started":"2024-11-05T05:54:01.731042Z","shell.execute_reply":"2024-11-05T05:54:01.73504Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.environ.get(\"HUGGINGFACEHUB_API_TOKEN\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:54:04.924551Z","iopub.execute_input":"2024-11-05T05:54:04.925006Z","iopub.status.idle":"2024-11-05T05:54:04.932245Z","shell.execute_reply.started":"2024-11-05T05:54:04.924963Z","shell.execute_reply":"2024-11-05T05:54:04.931201Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.llms import HuggingFaceHub\n\n# set Korean embedding and llm odel\nhf_embeddings = HuggingFaceEmbeddings(model_name=\"jhgan/ko-sroberta-multitask\")\n\nhf_llm = HuggingFaceHub(\n    repo_id=\"skt/kogpt2-base-v2\",\n    model_kwargs={\"task\": \"text-generation\"} ## question-answering tasK X. text-generation\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:05:21.449433Z","iopub.execute_input":"2024-11-05T05:05:21.450279Z","iopub.status.idle":"2024-11-05T05:05:57.401897Z","shell.execute_reply.started":"2024-11-05T05:05:21.450233Z","shell.execute_reply":"2024-11-05T05:05:57.400703Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import requests\nfrom langchain.schema import Document\nfrom bs4 import BeautifulSoup\n\n# By default, English documents (https://en.wikipedia.org))\n# def load_Wiki_docs(query):\n#     loader = WikipediaLoader(query=query, load_max_docs=1)\n#     documents = loader.load()\n    \n#     text_splitter = RecursiveCharacterTextSplitter(\n#         chunk_size=1000,\n#         chunk_overlap=200\n#     )\n#     splits = text_splitter.split_documents(documents)\n    \n#     return splits\n\n\n# For Korean query, get results from Korean wikipedia website and crawl and parse results\ndef load_Korean_wiki_docs(topic):\n\n    url = f\"https://ko.wikipedia.org/wiki/{topic}\"\n    \n    response = requests.get(url)\n    response.raise_for_status()  # raise Exception when error occurs\n\n    # HTML parsing and extract body contents\n    soup = BeautifulSoup(response.text, 'html.parser')\n    content = soup.find('div', {'class': 'mw-parser-output'})  # find div including body contents \n    \n    # Extract contents\n    paragraphs = content.find_all('p')\n    text = \"\\n\".join([p.get_text() for p in paragraphs])  # concat all context in <p> tags \n \n    # convert to Document object (required for LangChain)\n    documents = [Document(page_content=text, metadata={\"source\": url})]\n    \n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=1000,\n        chunk_overlap=200\n    )\n    splits = text_splitter.split_documents(documents)\n    \n    return splits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:06:21.175046Z","iopub.execute_input":"2024-11-05T05:06:21.175525Z","iopub.status.idle":"2024-11-05T05:06:21.379554Z","shell.execute_reply.started":"2024-11-05T05:06:21.175483Z","shell.execute_reply":"2024-11-05T05:06:21.378546Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_vectorstore(splits): \n    vectorstore = Chroma.from_documents(documents=splits, embedding=hf_embeddings)\n    return vectorstore","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:07:20.197045Z","iopub.execute_input":"2024-11-05T05:07:20.19748Z","iopub.status.idle":"2024-11-05T05:07:20.202533Z","shell.execute_reply.started":"2024-11-05T05:07:20.197436Z","shell.execute_reply":"2024-11-05T05:07:20.201425Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"topic = \"흑백요리사\"\n# Load wikipedia documents for this topic\nsplits = load_Korean_wiki_docs(topic)\n# Create vectorstore with this fetched docs\nvectorstore = create_vectorstore(splits)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:07:20.595737Z","iopub.execute_input":"2024-11-05T05:07:20.596227Z","iopub.status.idle":"2024-11-05T05:07:22.180211Z","shell.execute_reply.started":"2024-11-05T05:07:20.596182Z","shell.execute_reply":"2024-11-05T05:07:22.179081Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"splits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:09:41.073102Z","iopub.execute_input":"2024-11-05T05:09:41.073937Z","iopub.status.idle":"2024-11-05T05:09:41.081452Z","shell.execute_reply.started":"2024-11-05T05:09:41.073885Z","shell.execute_reply":"2024-11-05T05:09:41.080175Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1. Use langchain RAG","metadata":{}},{"cell_type":"code","source":"def create_rag_chain(vectorstore):\n    prompt_template = \"\"\"문맥을 참고하여 질문에 정확하고 간결하게 답하십시오.\n    문맥: {context}\n    질문: {question}\n    답변:\"\"\"\n    \n    PROMPT = PromptTemplate(\n        template=prompt_template, input_variables=[\"context\", \"question\"]\n    )\n\n    chain_type_kwargs = {\"prompt\": PROMPT}\n\n    # Make context shorter\n    # def short_context(context, max_length=300):\n    #     return context[:max_length] if len(context) > max_length else context\n    \n    # class ShortContextRetriever(BaseRetriever):\n    #     def __init__(self, retriever):\n    #         super().__init__()\n    #         self._retriever = retriever\n        \n    #     def get_relevant_documents(self, query):\n    #         docs = self._retriever.get_relevant_documents(query)\n    #         for doc in docs:\n    #             doc.page_content = short_context(doc.page_content)\n    #         return docs\n    \n    # retriever = ShortContextRetriever(vectorstore.as_retriever())\n\n    qa_chain = RetrievalQA.from_chain_type(\n        llm=hf_llm,\n        chain_type=\"stuff\",\n        retriever=vectorstore.as_retriever(),\n        chain_type_kwargs=chain_type_kwargs,\n        return_source_documents=True\n    )\n    \n    return qa_chain","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:13:26.600056Z","iopub.execute_input":"2024-11-05T05:13:26.600547Z","iopub.status.idle":"2024-11-05T05:13:26.607815Z","shell.execute_reply.started":"2024-11-05T05:13:26.600505Z","shell.execute_reply":"2024-11-05T05:13:26.606658Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# create langchang RAG chain\nqa_chain = create_rag_chain(vectorstore)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:13:34.510219Z","iopub.execute_input":"2024-11-05T05:13:34.510688Z","iopub.status.idle":"2024-11-05T05:13:34.517443Z","shell.execute_reply.started":"2024-11-05T05:13:34.510645Z","shell.execute_reply":"2024-11-05T05:13:34.516281Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"question = \"심사위원을 누가 맡았어?\"\n\n# result = qa_chain({\"query\": question})\nresult = qa_chain.invoke({\"query\": question})\n\nprint (\"결과:\")\nprint(result[\"result\"])\n\nprint(\"출처:\")\nfor doc in result[\"source_documents\"]:\n    print(doc.page_content)\n    print(\"---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:15:04.134637Z","iopub.execute_input":"2024-11-05T05:15:04.135741Z","iopub.status.idle":"2024-11-05T05:15:04.843433Z","shell.execute_reply.started":"2024-11-05T05:15:04.135676Z","shell.execute_reply":"2024-11-05T05:15:04.842203Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"docs = vectorstore.as_retriever().get_relevant_documents(question)\ndocs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:18:43.16827Z","iopub.execute_input":"2024-11-05T05:18:43.168703Z","iopub.status.idle":"2024-11-05T05:18:43.293426Z","shell.execute_reply.started":"2024-11-05T05:18:43.168658Z","shell.execute_reply":"2024-11-05T05:18:43.29224Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"docs = vectorstore.similarity_search(question, k=4)\ndocs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:19:58.448151Z","iopub.execute_input":"2024-11-05T05:19:58.448619Z","iopub.status.idle":"2024-11-05T05:19:58.526084Z","shell.execute_reply.started":"2024-11-05T05:19:58.448576Z","shell.execute_reply":"2024-11-05T05:19:58.524804Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# It seems vectorDB loading from embedding model works fine, but seems llm model does not.\n# Some Korean llm model seems to work fine in text-generation task, but for Question-Ansering task, we might need another approach.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Use QA pipeline with vectorstor similarity search","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n\n# Load model and tokenizer\nmodel_name = \"yjgwak/klue-bert-base-finetuned-squard-kor-v1\"\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# Set Q_A pipeline\nqa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:21:45.59742Z","iopub.execute_input":"2024-11-05T05:21:45.598338Z","iopub.status.idle":"2024-11-05T05:22:10.132361Z","shell.execute_reply.started":"2024-11-05T05:21:45.598295Z","shell.execute_reply":"2024-11-05T05:22:10.131037Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example: define question and context \nquestion = \"오늘 날씨 어때?\"\ncontext = \"오늘의 날씨는 맑고 따뜻한 기온이 유지될 것으로 보입니다.\"\n\n# model chain\nresult = qa_pipeline(question=question, context=context)\n\n# Result\nprint(\"질문:\", question)\nprint(\"답변:\", result['answer'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:23:41.58642Z","iopub.execute_input":"2024-11-05T05:23:41.586883Z","iopub.status.idle":"2024-11-05T05:23:41.704671Z","shell.execute_reply.started":"2024-11-05T05:23:41.586844Z","shell.execute_reply":"2024-11-05T05:23:41.703573Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# search context in VectorStore\ndef retrieve_context(question, vectorstore):\n    docs = vectorstore.similarity_search(question, k=4)\n    if docs:\n        return \" \".join([doc.page_content for doc in docs])\n        # return docs[0].page_content  # return first relevant doc\n    else:\n        return None\n\n# Generate answer based on query and searched context similar to RAG chain\ndef answer_question_with_context(question, vectorstore):\n    context = retrieve_context(question, vectorstore)\n    if context:\n        result = qa_pipeline(question=question, context=context)\n        return result['answer'], context  # return answer and used source doc\n    else:\n        return \"관련 문맥을 찾지 못했습니다.\", None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:27:40.729974Z","iopub.execute_input":"2024-11-05T05:27:40.731025Z","iopub.status.idle":"2024-11-05T05:27:40.739313Z","shell.execute_reply.started":"2024-11-05T05:27:40.730977Z","shell.execute_reply":"2024-11-05T05:27:40.738151Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example\nquestion = \"심사위원을 누가 맡았어?\"\n\nanswer, used_context = answer_question_with_context(question, vectorstore)\n\nprint(\"질문:\", question)\nprint(\"답변:\", answer)\nprint(\"사용된 문맥:\", used_context)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T05:27:41.283766Z","iopub.execute_input":"2024-11-05T05:27:41.28422Z","iopub.status.idle":"2024-11-05T05:27:41.580645Z","shell.execute_reply.started":"2024-11-05T05:27:41.284179Z","shell.execute_reply":"2024-11-05T05:27:41.579544Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}